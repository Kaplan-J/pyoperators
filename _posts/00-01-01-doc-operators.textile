---
layout: post
title: 2. Operators
category: doc
---

h2. 2.1. <a name="using_operators"></a> Using operators

The @Operator@ class and its subclasses are function factories. It means that in order to perform computations using an operator class, we first need to create an instance of it:

{% highlight python %}
A = FftOperator(1024)
{% endhighlight %}

and then use the instance as a function. The object @A@ is a Python callable and takes "numpy":http://numpy.scipy.org 's N-dimensional array object as inputs and outputs:

{% highlight python %}
>>> input = np.arange(1024, dtype=complex)
>>> output = A(input)
Info: Allocating (1024,) complex128 = 0.015625 MiB in FftOperator.
{% endhighlight %}

When using the operator in such a way, a no-side-effect policy is enforced: it is garanteed that the input array will not be modified and as a consequence, a new buffer will be allocated every time the operator is called.

<a name="output_argument"></a>Similarly to ufuncs, such behaviour can be changed by providing the output array:

{% highlight python %}
>>> output = np.empty(1024, dtype=complex)
>>> A(input, output)
{% endhighlight %}

"In-place operations":#inplace_operators can be performed in a similar way by providing the input array as the output.

In this documentation, the same term __operator__ will be used for the @Operator@ class, subclasses and instances, though the context will disambiguate the meaning.


h2. 2.2. <a name="manipulating_operators"></a> Manipulating operators

Operators are easy to manipulate: they can be multiplied by a scalar, combined by addition, composition, element-wise (Hadamard) multiplication or "partition":#partition. The synthax uses the usual arithmetic signs, but be careful that the @*@ sign currently stands for composition (and not element-wise multiplication), following the convention for linear operators.

{% highlight python %}
>>> o1 = DiagonalOperator([1., 2.])
>>> o2 = DiagonalOperator([1., 1.])
>>> (3 * o1)([2., 2.])
array([  6.,  12.])
>>> (o1 + o2)([2., 2.])
array([ 4.,  6.])
>>> (o1 * o2)([2., 2.])  # same as o1(o2)
array([ 2.,  4.])
{% endhighlight %}

Unless an algebraic simplification is possible, the resulting operator is a composite operator:

<div class="definition">
|  *addition*       | @AdditionOperator@ |
|  *composition*    | @CompositionOperator@ |
|  *multiplication* | @MultiplicationOperator@ |
|/2.  *partition*   | @BlockOperator@, @BlockRowOperator@|
|@BlockDiagonalOperator@, @BlockColumnOperator@|
</div>
<hr>

The @*@ sign may be confusing when multiplying non-linear operators and currently, the only way to perform element-wise multiplication is to call the composite operator:

{% highlight python %}
>>> MultiplicationOperator([o1, o2])([2., 2.])
array([ 4.,  8.])
{% endhighlight %}

The conjugate, transpose, adjoint and inverse operators, when defined, can be obtained by using the following attributes:

<div class="definition">
| *conjugate* | @.C@ |
| *transpose* | @.T@ |
| *adjoint*   | @.H@ |
| *inverse*   | @.I@ |
</div>
<hr>

For example:

{% highlight python %}
>>> o = Operator()
>>> o.T.C is o.H
True
>>> o = Operator(flags='real,symmetric')
>>> o.T is o.H is o
True
{% endhighlight %}


h2. 2.3. <a name="creating_operators"></a> Creating a new operator

Operators can be created in two ways. The first one is to define a direct function which will replace the usual matrix-vector operation and to instantiate the @Operator@ class by passing the function as the first argument:

{% highlight python %}
>>> def f(x, out):
...     out[...] = 2 * x
>>> P = Operator(f)
{% endhighlight %}

Transforming a single-argument "ufunc":http://docs.scipy.org/doc/numpy/reference/ufuncs.html into an @Operator@ instance is straightforward:

{% highlight python %}
>>> sqrt = Operator(np.sqrt)
{% endhighlight %}

The alternative way is more flexible, it consists in subclassing the @Operator@ class:

{% highlight python %}
>>> class MyOperator(Operator):
...     def __init__(self, coef):
...         self.coef = coef          
...         Operator.__init__(self)
...     def direct(self, x, out):
...         out[...] = self.coef * x
...
>>> P = MyOperator(2)
{% endhighlight %}




h2. 2.4. <a name="operator_flags"></a> Operator's flags

An operator __P__ can have the following algebraic properties, accessible with the @flags@ attribute:

<div class="definition">
|  *linear*     | |
|  *real*       | conj __P__  = __P__ |
|  *symmetric*  | __P__ ^T^   = __P__ |
|  *hermitian*  | __P__ ^H^   = __P__ |
|  *idempotent* | __P__ __P__ = __P__ |
|  *involutary* | __P__ __P__ = __I__ |
|  *orthogonal* | __P__ ^T^ __P__ = __I__ |
|  *unitary*    | __P__ ^H^ __P__ = __I__ |
</div>
<hr>

They can be set using the @flags@ keyword:

{% highlight python %}
>>> def f(x, out):
...     out[...] = -x
>>> P = Operator(direct=f, flags='symmetric,involutary')
{% endhighlight %}

or by using operator decorators:

{% highlight python %}
>>> @decorators.symmetric
... @decorators.involutary
... class MyOperator(Operator):
...     def direct(self, x, out):
...         out[...] = -x
...
>>> P = MyOperator()
{% endhighlight %}

These flags are used to simplify expressions:

{% highlight python %}
>>> C = Operator(flags='idempotent')
>>> C * C is C
True
>>> D = Operator(flags='involutary')
>>> D * D
IdentityOperator()
{% endhighlight %}

Other properties are described by the @flags@ attribute:

<div class="definition">
|  *square*            | input and output have the same shape |
|  *shape_input*       | explicit, implicit or unconstrained ("more info":#operator_shapes) |
|  *shape_output*      | explicit, implicit or unconstrained ("more info":#operator_shapes) |
|  *inplace*           | handle inplace operations ("more info":#inplace_operators)|
|  *inplace_reduction* | handle inplace reductions ("more info":#inplace_reductions)|
</div>
<hr>



h2. 2.5. <a name="operator_rules"></a> Operator's rules

PyOperators has the ability to reduce arithmetic expressions involving operators. This is achieved by means of binary rules which are applied to pairs of operators. Such a rule is specific to an operation (addition, multiplication or composition). It is binary and has the form 'subject &rarr; predicate'. The subject is a pair of properties that will be matched against the pair of operators. The properties are represented by a string. One of them stands for the reference operator, it is the operator to which the rule is attached.

<div class="definition">
|@'.'@     | reference operator |
|@'.C'@    | reference operator's conjugate|
|@'.T'@    | reference operator's transpose|
|@'.H'@    | reference operator's ajoint|
|@'.I'@    | reference operator's inverse|
|@'{...}'@ | instance of the class '...'|
|@'{self}'@| instance of the reference operator's class |
</div>

For instance and for a given operator @P@, the subject @'..'@ will match the pair (@P@, @P@), the subject @'.T.'@ the pair (@P.T@, @P@) and @'..H'@ the pair (@P@, @P.H@). When the pair of operators is matched by the subject, it is replaced by the predicate:

<div class="definition">
|@'.'@     | reference operator |
|@'.C'@    | reference operator's conjugate|
|@'.T'@    | reference operator's transpose|
|@'.H'@    | reference operator's ajoint|
|@'.I'@    | reference operator's inverse|
|@'1'@     | identity |
|function  | callback function|
</div>

For a non-commutative operation (composition), the rules of the left-hand side and right-hand side operators are combined:

* if one of the operator is a subclass of the other, its rules have higher priority
* otherwise, the rules of the right-hand side operator have higher priority

Rules attached to an operators are also prioritised:

* newer rules have higher priority
* non-matching-class rules have higher priority
* matching-class rules have a priority increasing with the depth of subclassing: the more specific the rule is, the higher priority it&nbsp;is.

Let's examine some examples for the composition operation:

* @'.T.'@ &rarr; @'1'@: if the expression @P.T*P@ is matched, it will be replaced by the identity. This is how the orthogonal property is translated into a rule.
* @'..I'@ &rarr; @'1'@: if the expression @P*P.I@ is matched, it will be replaced by the identity.
* @'.{IdentityOperator}'@ &rarr; @'.'@: if @P@ is composed by an instance of the identity operator,  the pair will be replaced by @P@
* @'.{self}'@ &rarr; @myfunc()@: if @P@ is composed by an instance of its class, the callback function @myfunc@ will be called and the pair of operators will be replaced by the result of this function, unless it is @None@, in which case the pair of operators is unchanged.

The rules attached to an operator are stored in the @rules@ attribute. They can be added by using the @set_rule@ method, which has 3 arguments:

* the subject
* the predicate
* the operation (@AdditionOperator@, @CompositionOperator@, @MultiplicationOperator@)

The predicate can be a function, in which case it must be a static method with two arguments for the pair of operators that matches the subject. Rules, such as the ones set in the superclass, can be deleted with the @del_rule@ method. In the following example, we construct an operator @Power@ that raises its input to a specified power. We add a rule to reduce the composition of two instances of the @Power@ class.

{% highlight python %}
>>> @decorators.square
... class Power(Operator):
...     def __init__(self, exponent):
...         Operator.__init__(self)
...         self.exponent = exponent
...         self.set_rule('.{Power}', self.rule_power, CompositionOperator)
...     def direct(input, output):
...         output[...] = input ** self.exponent
...     @staticmethod
...     def rule_power(p1, p2):
...         return Power(p1.exponent * p2.exponent)
...
>>> p1 = Power(2)
>>> p2 = Power(3)
>>> p = p1(p2)
>>> type(p)
__main__.Power
>>> p.exponent
6
{% endhighlight %}

h2. 2.6. <a name="associated_operators"></a> Operator's associated operators

Not documented. API might change in version {{ site.version_stable | plus:'0.1' }}.




h2. 2.7. <a name="operator_shapes"></a> Operator's input and output shapes

The @Operator@ class has a flexible way to deal with inputs and outputs. Its output shape can be:

<div class="definition">
*explicit:* the operator can only return arrays of a specified shape.

*implicit:* the output shape can be derived from the input shape through the method @reshapeout@.

*unconstrained:* the output shape does not depend on the input shape.
</div>

Likewise, its input shape can be:

<div class="definition">
*explicit:* the operator can only apply over arrays of a specified shape.

*implicit:* the operator can only apply over arrays whose shape is derived from the output shape through the method @reshapein@.

*unconstrained:* any input shape can be handled by the operator.
</div>

The operator's flags record this information in the @shape_input@ and @shape_output@ attributes. If the output (input) shape is

* explicit: the operator's attribute @shapeout@(@in@) is equal to that tuple. The @reshapeout@(@in@) method does not need to be defined.
* implicit: the attribute @shapeout@(@in@) is @None@ and the method @reshapeout@(@in@) applied over the input (output) shape must return the output (input) shape.
* unconstrained: the attribute @shapeout@(@in@) is None.  The @reshapeout@(@in@) method returns @None@.

h3. Operator with explicit input and output shape.

The explicit shapes are specified using the @shapein@ and @shapeout@ keywords. The following example appends a zero to a fixed-size input.

{% highlight python %}
>>> class Op(Operator):
...     def __init__(self, value):
...         Operator.__init__(self, shapein=3, shapeout=4)
...         self.value = value
...     def direct(self, input, output):
...         output[0:3] = input
...         output[3] = self.value
...
>>> op = Op(0.)
>>> op.shapein, op.shapeout
((3,), (4,))
>>> op([3., 2. ,1.])
array([3., 2., 1., 0.])
{% endhighlight %}

h3. Operator with implicit input shape and explicit output shape.

This case does not happen because the input shape can be obtained from the explicit output shape and the @reshapein@ method.

h3. Operator with unconstrained input shape and explicit output shape.

Such operator is obtained by only setting the @shapeout@ keyword. The following example returns an array of size 2 whose elements are the sum and product of the input elements.

{% highlight python %}
>>> class Op(Operator):
...     def __init__(self):
...         Operator.__init__(self, shapeout=2)
...     def direct(self, input, output):
...         output[0] = np.sum(input)
...         output[1] = np.product(input)
...
>>> op = Op()
>>> op.shapein, op.shapeout
(None, (2,))
>>> op([1., 2., 3., 4.])
array([ 10., 24.])
{% endhighlight %}


h3. Operator with explicit input shape and implicit output shape

This case does not happen because the output shape can be obtained from the explicit input shape and the @reshapeout@ method.

h3. Operator with implicit input and output shape

This operator defines a @reshapein@ and @reshapeout@ method. @Square@-decorated operators are examples of this kind of operators: their @reshapein@ and @reshapeout@ methods simply are @lambda x:x@. The interest for an implicit output shape operator of also handling implicit input shapes arises when a reverse operator such as @.T@ or @.H@ is defined, for which the @reshapein@(@out@) methods are swapped. The operator in the following example adds a zero to its input.

{% highlight python %}
>>> @decorators.linear
... class Op(Operator):
...     def direct(self, input, output):
...         output[:-1] = input
...         output[-1] = 0
...     def transpose(self, input, output):
...         output[...] = input[:-1]
...     def reshapeout(self, shapein):
...         if shapein is None: return None
...         return (shapein[0]+1,)
...     def reshapein(self, shapeout):
...         if shapeout is None: return None
...         return (shapeout[0]-1,)
...
>>> op = Op()
>>> op.shapein, op.shapeout
(None, None)
>>> op([1,2,3])
array([1, 2, 3, 0])
>>> op.T([1, 2, 3, 0])
array([1, 2, 3])
>>> np.array_equal(op.T.todense(4), op.todense(3).T)
True
{% endhighlight %}

h3. Operator with unconstrained input shape and implicit output shape

This operator can handle arbitrary inputs and its output dimensions are derived from those of the input. To obtain such operator, one simply has to define a @reshapeout@ method, which takes the input shape as input and returns the output shape. The following example stretches the input by a factor 2 along the first dimension.

{% highlight python %}
>>> class Op(Operator):
...     def direct(self, input, output):
...         output[::2,...] = input
...         output[1::2,...] = input
...     def reshapeout(self, shapein):
...         if shapein is None:
...             return None
...         return (2*shapein[0],) + shapein[1:]
...
>>> op = Op()
>>> op.shapein, op.shapeout
(None, None)
>>> op.reshapeout((2,3))
(4,3)
>>> op([[1, 2, 3],
...     [2, 3, 4]])
array([[1, 2, 3],
       [1, 2, 3],
       [2, 3, 4],
       [2, 3, 4]])
{% endhighlight %}


h3. Operator with explicit input shape and unconstrained output shape

Such operator is obtained by only setting the @shapein@ keyword. The following example fills the output with an arithmetic progression whose coefficients are given by the two elements of the input.

{% highlight python %}
>>> class Op(Operator):
...     def __init__(self):
...         Operator.__init__(self, shapein=2)
...     def direct(self, input, output):
...         output[...] = input[0] + input[1] * np.arange(output.size).reshape(output.shape)
...
>>> op = Op()
>>> op.shapein, op.shapeout
((2,), None)
>>> output = np.empty((2,2), int)
>>> op([1, 2], output)
array([[1, 3],
       [5, 7]])
{% endhighlight %}

h3. Operator with implicit input shape and unconstrained output shape

This kind of operator is of limited interest and is shown here for completeness. Since there is no way to compute the output shape from the input, the "output argument":#output_argument must be provided. The operator in this example returns the input from which the last element has been removed.

{% highlight python %}
>>> class Op(Operator):
...     def direct(self, input, output):
...         output[...] = input[:-1]
...     def reshapein(self, shapeout):
...         if shapeout is None:
...             return None
...         return (shapeout[0] + 1,)
...
>>> op = Op()
>>> op.shapein, op.shapeout
(None, None)
>>> op([1,2,3])
ValueError: The output shape of an implicit input shape and unconstrained output shape operator cannot be inferred.
>>> output = np.empty(4)
>>> op([1.,2.,3.,4.,5.], output)
array([ 1.,  2.,  3.,  4.])
>>> op(np.arange(4.), output)
ValueError: The input has an invalid shape '(4,)'. Expected shape is '(5,)'.
{% endhighlight %}

h3. Operator with unconstrained input and output shape

This kind of operator is the default: this behaviour is obtained by not setting the @shapein@ and @shapeout@ keywords and not defining the @reshapeout@ method. @ConstantOperator@ is an example of such an operator. If the output is not provided as argument, it is assumed that the output shape is that of the input. The following example fills the output with the value of the sum of the elements of the input.

{% highlight python %}
>>> class Op(Operator):
...     def __init__(self):
...         Operator.__init__(self)
...     def direct(self, input, output):
...         output[...] = np.sum(input)
...
>>> op = Op()
>>> op.shapein, op.shapeout
(None, None)
>>> output = np.empty((2,2), int)
>>> op([2, 1], output)
array([[3, 3],
       [3, 3]])
{% endhighlight %}




h2. <a name="operator_dtype"></a> 2.8. Operator's data type

The operator's data type is a data type object (an instance of "numpy.dtype":http://docs.scipy.org/doc/numpy/reference/arrays.dtypes.html class). It can be set using the @dtype@ keyword.

{% highlight python %}
>>> a = Operator(dtype=np.float32)
>>> a.dtype
dtype('float32')
{% endhighlight %}

It is used to determine the output data type, as being the common type of the operator and input data types, following the standard coercion rules. For example:

{% highlight python %}
>>> a = DiagonalOperator([1, 2])
>>> a.dtype
dtype('int64')
>>> a([1, 1j]).dtype
dtype('complex128')
>>> a(np.array([2, 2], np.uint8)).dtype
dtype('int64')
{% endhighlight %}

The operator's data type can be equal to None (the default), in which case the output data type is always the input data type.




h2. <a name="class_propagation"></a> 2.9. Class propagation

An operator propagates the class of the input array, if the latter subclasses @numpy.ndarray@:

{% highlight python %}
>>> class ndarray2(np.ndarray):
...     pass
>>> type(I(ndarray2((2,2))))
__main__.ndarray2
{% endhighlight %}

It is possible to change the subclass too, by using the @classout@ keyword:

{% highlight python %}
>>> class ndarray3(np.ndarray):
...     pass
>>> I2 = IdentityOperator(classout=ndarray3)
>>> type(I2(ndarray((2,2))))
__main__.ndarray3
>>> type(I2(ndarray2((2,2))))
__main__.ndarray3
{% endhighlight %}



h2. <a name="attribute_propagation"></a> 2.10. Attribute propagation

An operator also propagates attributes:

{% highlight python %}
>>> class ndarray2(np.ndarray):
...     pass
...
>>> x = ndarray2((2,2))
>>> x.foo = 'bar'
>>> I(x).foo
'bar'
{% endhighlight %}

It is also possible to add or change an attribute, by setting the @attrout@ keyword to a dictionary whose keys are the attribute names and whose values are the attribute values:

{% highlight python %}
>>> I2 = IdentityOperator(attrout={'foo':'new_bar'})
>>> I2(x).foo
'new_bar'
>>> x.foo
'bar'
>>> I2(np.ones((2,2))).foo
'new_bar'
{% endhighlight %}

More flexibility is possible by passing a function, instead of a dictionary, to the @attrout@ keyword. This function expects a dictionary whose keys are the attribute names and whose values are the attribute values (it is the output's @__dict__@):

{% highlight python %}
>>> class I2Operator(IdentityOperator):
...     def __init__(self):
...         IdentityOperator.__init__(self, attrout=self.add_history)
...     def add_history(self, attr):
...         from time import ctime
...         if 'history' not in attr:
...             attr['history'] = []
...         attr['history'] += [ctime() + ' : ' + self.__class__.__name__]
...
>>> I2 = I2Operator()
>>> I2(I2(0)).history
{% endhighlight %}



h2. <a name="inplace_operators"></a> 2.11. In-place and out-of-place operators

<div class="definition">
*in-place operator:* operator whose @direct@ method can handle input and output arguments pointing to the same memory location.

*out-of-place operator:* operator whose @direct@ method cannot.
</div>

Such a property is set by the @inplace@ decorator. For instance, the operator @DiagonalOperator@ is an in-place operator and the following computation

{% highlight python %}
>>> d = DiagonalOperator([1, 2])
>>> x = np.array([0, 1])
>>> d(x, x)
array([0, 2])
{% endhighlight %}

is done in-place and is equivalent to:

{% highlight python %}
>>> x = np.array([0, 1])
>>> x *= [1, 2]
{% endhighlight %}

An in-place operator also has to handle out-of-place operations. In the following example, the operation is performed out-of-place to satisfy the no-side-effect policy:

{% highlight python %}
>>> d = DiagonalOperator([1, 2])
>>> x = np.array([0, 1])
>>> y = d(x)
>>> y
array([0, 2])
{% endhighlight %}

which is equivalent to:

{% highlight python %}
>>> x = np.array([0, 1])
>>> y = x * [1, 2]
{% endhighlight %}

The in-place property is useful to avoid intermediate variables. To minimise the memory-cache transfers during a composition, an algorithm has been put in place to determine the intermediate variables to be extracted from the memory manager, by maximising the temporal locality (i.e. by reusing as much as possible the same memory area). This algorithm depends on:

* the parity of the number of out-of-place operators
* whether or not the input and the output of the composition point the same memory location (in-place or out-of-place composition)
* the size of the output, and if it is large enough to be reused in the intermediate computations.

As an example, let's consider the composition of an in-place operator @IN@ by an out-of-place operator @OUT@. The out-of-place composition

{% highlight python %}
>>> (IN * OUT)(input, output)
{% endhighlight %}

requires an intermediate variable only if the size of @OUT@ 's output is larger than that of the @output@ variable. Otherwise, the @output@ variable is used as @OUT@ 's output and the application of the operator @IN@ is performed in-place.

Concerning the in-place composition:

{% highlight python %}
>>> (IN * OUT)(input, input)
{% endhighlight %}

it is not possible to avoid the use of a temporary variable, since a buffer different from the @input@ variable is required for the @OUT@ operator.  The application of the operator @IN@ is performed out-of-place because its output is the @input@ variable.




h2. <a name="inplace_reductions"></a> 2.12. In-place reductions

<div class="definition">
An operator that can do in-place reductions is an operator that can add, multiply (or else) its output to its output argument.
</div>

Let see how this property can be used to further remove the use of intermediate variables. First, let's assume that the operator @o2@ cannot do in-place reductions:

{% highlight python %}
>>> (o1 + o2)(input, output)
{% endhighlight %}

The following steps are performed:

* the variable @output@ is used as @o1@ 's output,
* a temporary variable is allocated (or retrieved from the memory manager),
* it is used as @o2@ 's output
* and is then added in-place to the @output@ variable.

If we now assume that the operator @o2@ can do in-place reductions, the intermediate variable is not required anymore:

* the variable @output@ is used as @o1@ 's output
* @o2@ updates the @output@ variable in-place.

One can enable such property by adding the keyword @operation@ to the operator's direct method.

{% highlight python %}
>>> class P(Operator):
...     def direct(self, input, output, operation=assignment_operation):
...         operation(output, input)
...
>>> Q = sum(P() for k in range(0,3))
>>> output = np.empty(2)
>>> Q([1., 2.], output)
array([ 3.,  6.])
{% endhighlight %}

No intermediate variable is needed and all operations have been performed in-place. For the first operand, the @direct@ method of @Q@, which is an @AdditionOperator@, calls @P@ 's @direct@ method without the @operation@ keyword and consequently, the default function @assignment_function@ is used, which simply assigns the input to the output argument. The subsequent calls to @P@ set the @operation@ keyword to the @__iadd__@ function from Python's @operator@ module (If @Q@ was a @MultiplicationOperator@, it would be the function @operator.__imul__@), which result in adding the input into the output argument in-place. This property is even more interesting for cache locality when an operator's output is zero, except for a few values. In such a case, the operator would only have to update the non-zero values:

{% highlight python %}
>>> @decorators.linear
... class Projection(Operator):
...     def __init__(self, index):
...          self.index = index
...          Operator.__init__(self, shapein=1, shapeout=11)
...     def direct(self, input, output, operation=assignment_operation):
...         if operation is assignment_operation:
...             output[...] = 0
...         elif operation is not operator.__iadd__:
...             raise NotImplementedError()
...         output[self.index] += input
...
>>> Q = Projection(0) + Projection(5) + Projection(10)
>>> output = np.empty(11)
>>> Q([2.], output)
array([ 2.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  2.])
{% endhighlight %}


h2. <a name="partition"></a> 2.13. Operator partition

Currently, there are two ways to partition operators, depending on whether the partitioning is done in an already existing dimension or not.

<div class="definition">
|*Stack partition:*| outputs are stacked along a new dimension|
|*Chunk partition:*| outputs are concatenated along an existing dimension|
</div>
<hr>

h3. Stack partition

A stack partition operator is an instance of @BlockRowOperator@, initialised with the @new_axisin@ keyword, @BlockDiagonalOperator@ with the keywords @new_axisin@ or @new_axisout@ or @BlockColumnOperator@, initialised with the @new_axisout@ keyword. There is a strong constraint on the input and output shapes of the blocks, since they must be the same for all blocks. The partition along the specified axis is always explicit and is equal to a tuple of ones with as many elements as the number of blocks. In the following example is shown a stack partition block column operator:

{% highlight python %}
>>> C = BlockColumnOperator([I, 2*I, 3*I], new_axisout=0)
>>> C(np.ones(2))
array([[ 1.,  1.],
       [ 2.,  2.],
       [ 3.,  3.]])
{% endhighlight %}

The outputs of the blocks are stacked along the dimension specified by @new_axisout@ keyword, i.e the first one. The following example shows a stack partition block diagonal operator:

{% highlight python %}
>>> D = BlockDiagonalOperator([I, 2*I, 3*I], new_axisin=-1)
>>> x = np.arange(2*3).reshape((2,3))
>>> x
array([[0, 1, 2],
       [3, 4, 5]])
>>> D(x)
array([[ 0,  2,  6],
       [ 3,  8, 15]])
{% endhighlight %}

It can be seen that the first block @I@ is applied over @x[:,0]@, the second block @2*I@ over @x[:,1]@, and the third block @3*I@ over @x[:,2]@.

h3. Chunk partition

A chunk partition operator is an instance of @BlockRowOperator@, initialised with the @axisin@ keyword, @BlockDiagonalOperator@ with the keywords @axisin@ or @axisout@ or @BlockColumnOperator@, initialised with the @axisout@ keyword. There is a lesser constraint on the shapes of the partitioned input and output of the blocks: all dimensions must be same except along the partitioned dimension(s). The partition along the specified axis can be implicit or explicit, in which case the keyword @partitionin@ or @partitionout@ is set to this explicit partition. The following example shows a block diagonal chunk partition operator with an explicit partition

{% highlight python %}
>>> D = BlockDiagonalOperator([I, 2*I, 3*I], axisin=-1, partitionin=(2,3,2))
>>> D(np.ones(7))
array([ 1.,  1.,  2.,  2.,  2.,  3.,  3.])
{% endhighlight %}

It can be seen that the first block @I@ is applied over the two first elements, the second block @2*I@ over the three following elements, and the third block @3*I@ over the last two elements. Block row and block column chunk partition operators can handle implicit partitions:

{% highlight python %}
>>> C = BlockColumnOperator([I, 2*I, 3*I], axisout=-1)
>>> C(np.ones((2,2)))
array([[ 1.,  1.,  2.,  2.,  3.,  3.],
       [ 1.,  1.,  2.,  2.,  3.,  3.]])
{% endhighlight %}

Likewise, the outputs of the blocks are concatenated along the dimension specified by the @axisout@ keyword, i.e the last one.




h2. <a name="list"></a> 2.14. List of available operators

h3. Linear operators

* AdditionOperator
* BandOperator
* BlockRowOperator
* BlockDiagonalOperator
* BlockColumnOperator
* CompositionOperator
* ConstantOperator
* DiagonalOperator
* EigendecompositionOperator
* HomothetyOperator
* IdentityOperator
* MaskOperator
* MultiplicationOperator
* PackOperator
* ReshapeOperator
* SymmetricBandOperator
* TridiagonalOperator
* UnpackOperator
* WaveletOperator
* Wavelet2Operator
* ZeroOperator


h3. Non-linear operators

* ClipOperator
* MaximumOperator
* MinimumOperator
* NumexprOperator
* RoundOperator

More operators can be found in the project "Tamasis/PACS":http://pchanial.github.com/tamasis-map, such as complex and real fft operators, convolution, projection, discrete differences, compression, downsampling, MPI operators, etc.
There is an on-going work consisting in migrating the most generic ones into the pyoperators package.
